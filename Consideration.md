Thanks. Your consideration is valuable. But we must from music to generate "a single" connected trianglized spacetime. And I think the music really should treat like a discreted spacetime. 您知道的，生成性构成了音乐。如果我们不保持连续的生成性，那么其不应当在句法上被认为是同一首歌。但是是否在语义上可以认为是同一首歌，是值得哲学上的讨论的。

Do not build connectivity from geometry.

Build geometry from generativity.


Next, an important question is that. We have a trianglied spacetime data's json. It may generated from a GFT model, or just simply from a mid file utilize the above algorithm. Anyways, we need decode it into a music, in midi form. I think the most significant problem is that, (1) the structure has some symmetric. i.e., A node in the geometry, the original mid source may be C, but it can be decode to D, without problem, if other node also mapped to relative notes. ! They retain 相对不变性！and is isomorphic!! So, we may need some parameter to control this?, and (2) how to decide a decoding is music like quantitatively.. As this will be helpful in optimize GFT model...


Gauge / symmetry in the representation (many different MIDIs correspond to the same relational structure), and

A quantitative objective for “music-likeness” that you can optimize in GFT.

What you described (C→D shift with everything shifted) is exactly an invariance:

Pitch transposition: add a constant to all pitches

Often also time translation / tempo scaling (depending on your encoding)

Sometimes octave shifts, key-mode ambiguity, etc.

This is not a bug. It’s the same phenomenon as gauge freedom: your intermediate representation encodes relations, not absolute anchors.


yeah. So I think we should carefully consider. Triangled spacetime as intermediated representation, I think this is good. And in fact, the GFT want to study such latent geometry representation. But at least we need shows that the latent geometry representation can decoded into some similar music like the original one. Because symmetric, it can decode to various music, this should also can be control. But now it generate something seems total differ music? May be one problem is not time/distance preserving because normalization?

自己认为时间可能不存在。因此，变化才构成独立事件。自己支持想法：仅在notes变化时才构成事件。但是持续事件可以被编码到边的特性

自己悟了。
自己依然认为
1. face必须编码note，edge编码耦合，vertex编码结构变化性事件。
2. 宇宙没有时间的概念，只有事件与变化。
让我们考虑一个实例

拍1:  ●(C4)  ●(D3)  ●(E1)
      ↓      ↓      ↓
拍2:  ●(C4)  ●(D3)  ●(E1)
      
      [顶点：拍2→拍3转换]
      
拍3:  ●(C4)  ●(D3)  [E1消失]
      ↓      ↓
拍4:  ●(C4)  ●(D3)
      
      [顶点：拍4→拍5转换]
      
拍5:  ●(D#3) ●(E2)  ●(F5)
      ↓      ↓      ↓
拍6:  ●(D#3) ●(E2)  ●(F5)
      
      [顶点：拍6→拍7转换]
      
拍7:  ●(D#3) ●(E2)  [F5消失]
      ↓      ↓
拍8:  ●(E2)

我们可能可以编码其到spinfoam. 自己认为时间可能不存在。因此，变化才构成独立事件。自己支持想法：仅在notes变化时才构成事件。但是持续时间可以被编码到边的特性.

